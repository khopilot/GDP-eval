#!/bin/bash

# GDP Evaluation Framework Setup Script
# Automatically configures the environment and installs dependencies

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Functions
log_info() { echo -e "${GREEN}[INFO]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_step() { echo -e "${BLUE}[STEP]${NC} $1"; }

# Banner
echo -e "${GREEN}"
echo "╔══════════════════════════════════════════════╗"
echo "║     GDP Evaluation Framework Setup          ║"
echo "║     🇰🇭 Khmer Language Model Evaluation      ║"
echo "╚══════════════════════════════════════════════╝"
echo -e "${NC}"

# Check system requirements
log_step "Checking system requirements..."

# Check Python version
if ! command -v python3 &> /dev/null; then
    log_error "Python 3 is not installed. Please install Python 3.9 or higher."
    exit 1
fi

python_version=$(python3 -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
required_version="3.9"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" != "$required_version" ]; then
    log_error "Python $required_version or higher is required. Found: $python_version"
    exit 1
fi

log_info "Python $python_version detected ✓"

# Check for Docker (optional)
if command -v docker &> /dev/null; then
    log_info "Docker detected ✓"
    DOCKER_AVAILABLE=true
else
    log_warn "Docker not found. Docker features will be unavailable."
    DOCKER_AVAILABLE=false
fi

# Check for Git
if ! command -v git &> /dev/null; then
    log_warn "Git not found. Version control features will be limited."
fi

# Create virtual environment
log_step "Setting up Python virtual environment..."

if [ -d "venv" ]; then
    log_warn "Virtual environment already exists. Skipping creation."
else
    python3 -m venv venv
    log_info "Virtual environment created ✓"
fi

# Activate virtual environment
source venv/bin/activate

# Upgrade pip
log_step "Upgrading pip..."
pip install --upgrade pip --quiet

# Install dependencies
log_step "Installing Python dependencies..."
log_info "This may take a few minutes..."

if [ -f "requirements.txt" ]; then
    pip install -r requirements.txt --quiet
    log_info "Dependencies installed ✓"
else
    log_error "requirements.txt not found!"
    exit 1
fi

# Create necessary directories
log_step "Creating project directories..."
mkdir -p data/reference_files
mkdir -p outputs
mkdir -p logs
mkdir -p .cache
mkdir -p tests/fixtures
mkdir -p configs
log_info "Directories created ✓"

# Setup environment file
log_step "Setting up environment configuration..."

if [ ! -f ".env" ]; then
    if [ -f ".env.example" ]; then
        cp .env.example .env
        log_info "Created .env file from template"
        log_warn "Please edit .env and add your API keys"
    else
        log_warn ".env.example not found. Creating basic .env file..."
        cat > .env << EOF
# GDP Evaluation Framework Configuration
# Generated by setup.sh

# Free API Keys (Optional)
HUGGINGFACE_API_KEY=
GEMINI_API_KEY=

# Local Services
OLLAMA_URL=http://localhost:11434
REDIS_URL=redis://localhost:6379/0

# Settings
LOG_LEVEL=INFO
ENABLE_CACHE=true
OUTPUT_DIR=outputs
DATA_DIR=data
EOF
        log_info "Basic .env file created"
    fi
else
    log_info ".env file already exists ✓"
fi

# Check for Ollama
log_step "Checking for Ollama (local LLM)..."

if command -v ollama &> /dev/null; then
    log_info "Ollama detected ✓"

    # Check if Ollama is running
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        log_info "Ollama service is running ✓"

        # List available models
        available_models=$(ollama list 2>/dev/null | tail -n +2 | awk '{print $1}' | tr '\n' ' ')
        if [ -n "$available_models" ]; then
            log_info "Available models: $available_models"
        else
            log_warn "No models found. Pull a model with: ollama pull llama2"
        fi
    else
        log_warn "Ollama is installed but not running."
        log_info "Start Ollama with: ollama serve"
    fi
else
    log_warn "Ollama not found. Install from https://ollama.ai for local LLM support."
fi

# Docker setup (if available)
if [ "$DOCKER_AVAILABLE" = true ]; then
    log_step "Docker setup options..."
    echo ""
    echo "Docker is available. You can:"
    echo "  1. Run the full stack: docker-compose up"
    echo "  2. Run only services: docker-compose up redis ollama libretranslate"
    echo "  3. Build the image: docker build -t gdpval ."
    echo ""
fi

# Download sample data
log_step "Checking sample data..."

if [ ! -f "data/sample_tasks.json" ]; then
    log_warn "Sample data not found. Creating sample tasks..."
    # Sample data should already be created by previous steps
else
    log_info "Sample data found ✓"
fi

# Run basic tests
log_step "Running basic validation..."

python3 -c "
import sys
sys.path.insert(0, '.')
try:
    from src.core.task_loader import KhmerTaskLoader
    from src.providers.huggingface_provider import HuggingFaceProvider
    from src.utils.khmer_utils import KhmerTextProcessor
    print('✓ Core modules imported successfully')
except ImportError as e:
    print(f'✗ Import error: {e}')
    sys.exit(1)
" || {
    log_error "Module import failed. Check installation."
    exit 1
}

# Create quick start script
log_step "Creating quick start script..."

cat > quick_start.sh << 'EOF'
#!/bin/bash
# Quick start script for GDP Evaluation Framework

# Activate virtual environment
source venv/bin/activate

# Start services in background (optional)
if command -v ollama &> /dev/null; then
    echo "Starting Ollama..."
    ollama serve > logs/ollama.log 2>&1 &
    OLLAMA_PID=$!
    echo "Ollama started (PID: $OLLAMA_PID)"
    sleep 3
fi

# Run the demo
echo "Starting GDP Evaluation Demo..."
python demo.py

# Cleanup on exit
if [ -n "$OLLAMA_PID" ]; then
    kill $OLLAMA_PID 2>/dev/null
fi
EOF

chmod +x quick_start.sh
log_info "Quick start script created ✓"

# Final summary
echo ""
echo -e "${GREEN}═══════════════════════════════════════════════════════${NC}"
echo -e "${GREEN}    Setup Complete! 🎉${NC}"
echo -e "${GREEN}═══════════════════════════════════════════════════════${NC}"
echo ""
echo "Next steps:"
echo ""
echo "1. Configure API keys (optional but recommended):"
echo "   ${BLUE}nano .env${NC}"
echo ""
echo "2. Install Ollama for local LLM (recommended):"
echo "   ${BLUE}https://ollama.ai${NC}"
echo ""
echo "3. Run the demo application:"
echo "   ${BLUE}source venv/bin/activate${NC}"
echo "   ${BLUE}python demo.py${NC}"
echo ""
echo "   Or use the quick start script:"
echo "   ${BLUE}./quick_start.sh${NC}"
echo ""
echo "4. Access the web interface:"
echo "   ${BLUE}http://localhost:7860${NC}"
echo ""
echo "5. Run with Docker (optional):"
echo "   ${BLUE}docker-compose up${NC}"
echo ""
echo "For more information, see README.md"
echo ""
echo -e "${GREEN}Happy evaluating! សូមជោគជ័យ! 🇰🇭${NC}"