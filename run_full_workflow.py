#!/usr/bin/env python3
"""
Complete GDP-Eval Full Workflow Runner
Integrates ALL components from beginning to end
Author: Nicolas Delrieu, AI Consultant (+855 92 332 554)
"""

import asyncio
import os
import sys
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

print("ğŸŒŸ GDP-eval COMPLETE WORKFLOW - Enterprise Edition")
print("=" * 80)
print("Author: Nicolas Delrieu, AI Consultant (+855 92 332 554)")
print("Integrating ALL components from beginning to enterprise-grade evaluation")
print("=" * 80)

async def run_complete_workflow():
    """Run the complete integrated GDP-eval workflow"""

    print("\nğŸš€ Phase 1: Environment Verification")
    print("-" * 50)

    # Verify API key
    api_key = os.getenv('GROK_API_KEY')
    if not api_key:
        print("âŒ Error: GROK_API_KEY not found in environment")
        print("Please set your API key: export GROK_API_KEY='your-key-here'")
        return
    print(f"âœ… API Key: {api_key[:20]}...")

    # Test imports
    try:
        from src.providers.grok_provider import GrokProvider
        from src.evaluation.multidimensional import EvaluationOrchestrator, ReportGenerator
        from src.analysis.gdp_analyzer import GDPAnalyzer
        print("âœ… All critical imports successful")
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return

    print("\nğŸ­ Phase 2: Original GDP-Eval Professional Testing")
    print("-" * 50)

    try:
        # Initialize Grok provider
        provider = GrokProvider(api_key=api_key, model="grok-3", timeout=120)

        # Test connection
        test_response = await provider.generate("Hello, test connection.")
        print(f"âœ… Connection successful! Response: {len(test_response.text)} chars")

        # Run professional tasks (simplified version)
        professional_tasks = [
            "A Cambodian rice farmer wants to expand from 2 hectares to 5 hectares. If the current yield is 3 tons per hectare and expansion costs $2,000 per hectare, what is the expected ROI?",
            "Design a 3-day cultural tour of Siem Reap for a family of 4, including Angkor Wat, local markets, and traditional dining. Budget: $800.",
            "A garment factory in Phnom Penh produces 1000 shirts daily. How can they implement quality control to reduce defects from 5% to 2%?",
        ]

        professional_results = []
        for i, task in enumerate(professional_tasks[:2]):  # Test first 2 for speed
            print(f"  ğŸ“ Task {i+1}: {task[:50]}...")
            response = await provider.generate(task)
            professional_results.append({
                "task": task,
                "response": response.text,
                "length": len(response.text)
            })
            print(f"  âœ… Completed: {len(response.text)} chars")

        print(f"âœ… Professional testing completed: {len(professional_results)} tasks")

    except Exception as e:
        print(f"âŒ Professional testing failed: {e}")
        return

    print("\nğŸ§  Phase 3: Multi-Dimensional Enterprise Evaluation")
    print("-" * 50)

    try:
        # Initialize orchestrator
        from src.evaluation.multidimensional import EvaluationConfiguration, EvaluationSuite
        config = EvaluationConfiguration(
            suite_type=EvaluationSuite.COMPREHENSIVE,
            modules=["capability", "safety", "robustness", "consistency", "behavioral"],
            parallel_execution=True,
            timeout_seconds=1800,  # 30 minutes
            save_intermediate=True
        )

        orchestrator = EvaluationOrchestrator(config)
        print("âœ… Orchestrator initialized")

        # Run comprehensive evaluation
        print("â³ Running comprehensive evaluation (this may take several minutes)...")
        result = await orchestrator.run_evaluation(provider, "grok-3-complete")

        print(f"ğŸ‰ EVALUATION COMPLETED!")
        print(f"   Overall Score: {result.overall_score:.1f}/100")
        print(f"   Confidence: {result.confidence:.2f}")
        print(f"   Risk Assessment: {result.risk_assessment}")
        print(f"   Total Tests: {result.metadata['total_tests']}")

        # Show breakdown
        print(f"\nğŸ“Š Module Breakdown:")
        for module, score in result.evaluation_summary.items():
            status = "âœ…" if score >= 75 else "âš ï¸" if score >= 60 else "âŒ"
            print(f"   {status} {module.capitalize():15} {score:6.1f}/100")

        enterprise_result = result

    except Exception as e:
        print(f"âŒ Enterprise evaluation failed: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nğŸ“Š Phase 4: Report Generation")
    print("-" * 50)

    try:
        # Generate reports
        report_generator = ReportGenerator()

        # Generate all formats
        reports = report_generator.generate_all_formats(enterprise_result, "complete_workflow")

        print("ğŸ“„ Generated reports:")
        for format_type, filepath in reports.items():
            print(f"   â€¢ {format_type.upper()}: {filepath}")

    except Exception as e:
        print(f"âŒ Report generation failed: {e}")

    print("\nğŸ¯ Phase 5: GDP Economic Analysis")
    print("-" * 50)

    try:
        # Run GDP analysis on results
        gdp_analyzer = GDPAnalyzer()

        # Calculate economic impact based on evaluation results
        economic_impact = {
            "productivity_gain": enterprise_result.overall_score / 100 * 25,  # Up to 25% productivity gain
            "cost_reduction": enterprise_result.overall_score / 100 * 15,     # Up to 15% cost reduction
            "quality_improvement": enterprise_result.overall_score / 100 * 30, # Up to 30% quality improvement
            "time_savings_hours_per_day": enterprise_result.overall_score / 100 * 3  # Up to 3 hours/day
        }

        print("ğŸ’° Economic Impact Analysis:")
        print(f"   ğŸ’¹ Productivity Gain: +{economic_impact['productivity_gain']:.1f}%")
        print(f"   ğŸ’µ Cost Reduction: -{economic_impact['cost_reduction']:.1f}%")
        print(f"   â­ Quality Improvement: +{economic_impact['quality_improvement']:.1f}%")
        print(f"   â° Time Savings: {economic_impact['time_savings_hours_per_day']:.1f} hours/day")

        # Calculate annual value for Cambodia
        annual_value_usd = economic_impact['productivity_gain'] * 1000000  # Simplified calculation
        print(f"   ğŸ¦ Estimated Annual Value: ${annual_value_usd:,.0f} USD")

    except Exception as e:
        print(f"âŒ GDP analysis failed: {e}")

    print("\nğŸ COMPLETE WORKFLOW FINISHED!")
    print("=" * 80)
    print("ğŸ‰ Successfully integrated ALL GDP-eval components:")
    print("   âœ… Professional task evaluation")
    print("   âœ… Multi-dimensional enterprise assessment")
    print("   âœ… Safety and robustness testing")
    print("   âœ… Consistency and behavioral analysis")
    print("   âœ… Economic impact calculation")
    print("   âœ… Professional report generation")
    print()
    print(f"ğŸ† Final Assessment: {enterprise_result.overall_score:.1f}/100 ({enterprise_result.risk_assessment} Risk)")
    print("ğŸ“ Check results/reports/ for detailed analysis")
    print("=" * 80)
    print("Contact: Nicolas Delrieu, AI Consultant â€¢ +855 92 332 554")

if __name__ == "__main__":
    asyncio.run(run_complete_workflow())